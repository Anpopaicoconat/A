{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rubert news",
      "provenance": [],
      "collapsed_sections": [
        "Jf9fUoC-4nLK",
        "F1yE-ES-4vX5"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "462ad225bb554ad68329f8996ee15812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5f77f4579716472b927a7f00484d5f4c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_06a90b79df8a434abaae4a63c9c3f8e0",
              "IPY_MODEL_526efb15304e49329377982bd6660d51"
            ]
          }
        },
        "5f77f4579716472b927a7f00484d5f4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "06a90b79df8a434abaae4a63c9c3f8e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "state": {
            "_view_name": "TextView",
            "style": "IPY_MODEL_09a57d02dd154bbeb0799adbc571c71c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "TextModel",
            "placeholder": "Введите новость",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Главное инновационное предприятие Алтайского края  Барнаульский завод высоких технологий БЗВТ  представило публике биочип удачно протестированный на шимпанзе. Деньги на грандиозный проект были выделены наукоградом Сколково а для его реализации привлекли лучших биологов и кибернетиков Алтая. Подопытных животных ученым предоставил местный зоопарк. Теоретические работы были проведены в полном объёме в начале года затем в опытном цеху БЗВТ изготовили прототипы чипа и вживили их обезьянам. На носителях записаны группы крови животных их родословные и истории заболеваний. Инновация была высоко оценена региональным Министерством здравоохранения. Создатели чипа рассчитывают на то что вскоре такие устройства будут успешно применяться и на людях тоже.",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "continuous_update": true,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1d3862ec2d184c6c9a98290893b4e759"
          }
        },
        "526efb15304e49329377982bd6660d51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "state": {
            "_view_name": "ButtonView",
            "style": "IPY_MODEL_a180660713b642c7842819c8b36f0492",
            "_dom_classes": [],
            "description": "предсказание",
            "_model_name": "ButtonModel",
            "button_style": "",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "tooltip": "",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "layout": "IPY_MODEL_7dc49677476d476dbfa3263d12aa0270",
            "_model_module": "@jupyter-widgets/controls",
            "icon": ""
          }
        },
        "09a57d02dd154bbeb0799adbc571c71c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1d3862ec2d184c6c9a98290893b4e759": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "95%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": "100%",
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a180660713b642c7842819c8b36f0492": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ButtonStyleModel",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "button_color": null,
            "font_weight": "",
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7dc49677476d476dbfa3263d12aa0270": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anpopaicoconat/A/blob/master/rubert_news.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jf9fUoC-4nLK"
      },
      "source": [
        "# Предисловие"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDruOk_U5yeb"
      },
      "source": [
        "## Цели проекта\n",
        "Создание нейронной сети, которая способна определять достоверность новостей \n",
        "\n",
        "## Задачи проекта\n",
        "\n",
        "*   Изучение новостных порталов\n",
        "*   Сбор данных и формирование обучающей и тестовой выборки\n",
        "*   Проектирование нейронной сети\n",
        "*   Реализация нейронной сети\n",
        "*   Обучение и тестирование нейронной сети\n",
        "\n",
        "\n",
        "## Актуальность\n",
        "\n",
        "В настоящее время, объёмы информации в интернете увеличиваются в геометрической прогрессии, а влияние такой информации растёт каждый день. Следовательно, возникает потребность в определении правдивой информации и отсеивании фейковой.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cs8C_hviF0I4"
      },
      "source": [
        "## Коротко о собранном новостном корпусе\n",
        "Целью проекта являлось создание эффективной архитектуры для решения конкретной задачи, по этому для демонстрации ее работы мы выбрали свободную выборку составленную Сбербанком для одного из соревнований.\n",
        "\n",
        "Данный датасет состоит из пар класс-текст. Стоить отмеить, что текст новостей нуждается в предобработке. Кроме того данные является сильно несбалансированным, ввиду чего при подготовки их к обучению мы используем семплинг для создания избыточной выборки. Поскольку большая часть новостей являются правдой - нейронная сеть будет склонна доверять сказанному и с большей вероятностью определит класс True. Следующий подход оправдан на практике, поскольку в реальной жизни распределения новостей является именно таким, однако эти настройки можно менять, повышая чувствительность модели.\n",
        "\n",
        "Необходимо сказать, что большой массив новостей в выбоке относятся к 2018-2019 году. Это важный аспект потому, что модель обучающаяся на них будет находиться в потоке событий прошлых лет (то что казалось нам невероятным год назад сейчас является обыденным). Такой эффект неизбежен, нейронная сеть будет прибывать в контексте (временном, тематическом или любом другом) обучающей выбоке. Ввиду этого ее реакция на современные новости может быть несколько неожиданной, но с расширением новостного корпуса ее аналитические способности будут расти, повышая тем самым адекватность оценки в отрыве от временного контекста."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QuMblTGGDzU"
      },
      "source": [
        "## Что такое BERT и как это работает\n",
        "BERT — это модель нейронной сети предложенная Google, показавшая с большим отрывом state-of-the-art результаты на целом ряде задач. С помощью BERT можно создавать программы с ИИ для обработки естественного языка: отвечать на вопросы, заданные в произвольной форме, создавать чат-ботов, автоматические переводчики, анализировать текст и так далее.\n",
        "\n",
        "Оригинальный BERT говорит по английски, мы же использовали RuBERT - это та же архитектура, но переобученная на большом корпусе русского языка. Если говорить конкретнее за основу бралась модель rusentiment_bert от deeppavlov, предназначенная для анаиза эмоцинальной окраски высказывания.\n",
        "\n",
        "Нами был разработан конвеер для fine-tuning'a модели с целью распознования фейковых новостей, выбранны гиперпараметры для настройки модели (в блокноте заложена возможность их кастомизации для ваших эксперементов). И мы предлагаем вам ознакомиться с проделанной работой.\n",
        "Мы любим свой код и нам нечего скрывать, по этому по двойному нажатию на ячейку вы можете просмотреть исходный код. Для удобства взаимодействия сохраните блокнот себе на гугл диск и запускайте его в колабе. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvK71uFtXHo4"
      },
      "source": [
        "## Что же все таки у вас есть?\n",
        "В итоге мы имеем готовую гибкую систему классификации текстов. Здесь в полной мере реализована микросервисная архитектура и модель может быть в кратчайшие сроки внедрена в ваш продукт. Из коробки мы имеем взаимодействие через консоль, подключение по Rest API, исполнение через python код и много чего еще. \n",
        " \n",
        "Однако не все так хорошо. Практическая точность модели продолжает вызывать вопросы. Мы заняли 15 место во всероссийском рейтинге классификации фейков, но этого мало. Следует пояснить, что результаты метрик распространяются на конкретную однородную, гомогенную выборку и могут быть экстраполированы на большие данные, лишь в той мере в которой представленная выборка является репрезентативной. Что это значит? Это значит что для того что бы модель работала корректно ее нужно использовать для классификации реально существующих статей размещенных на новостных порталах (имеющих ту же природу, что новости содержащиеся в обучающей выборке). Чисто теоретически вы можете классифицировать любой текст, или даже не текст, а то что является строчным типом данных, и даже получить какой то результат, но он не будет являться показательным, поскольку модель для этого не предназначена. \n",
        " \n",
        "Наш проект постоянно развивается [здесь](https://colab.research.google.com/drive/13pEfAz_Lqflfg2t733U8EQ003AjpRDPz?usp=sharing) вы можете следить за обучением релевантной модели в реальном времени. Ведется разработка парсера новостей для непрерывного обновления обучающей выборки. Благодаря этому нейросеть всегда будет в курсе событий. Расширение базы данных повысит обобщающую способность модели, что со временем приведет к меньшей ее зависимости от релевантных новостей, поскольку она начнет различать более глубинные паттерны классов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1yE-ES-4vX5"
      },
      "source": [
        "# Хочу увидеть программный продукт"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBq675Bk49xd",
        "cellView": "form",
        "outputId": "e99dcc40-5eed-412d-a604-a6a8ff833fd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78,
          "referenced_widgets": [
            "462ad225bb554ad68329f8996ee15812",
            "5f77f4579716472b927a7f00484d5f4c",
            "06a90b79df8a434abaae4a63c9c3f8e0",
            "526efb15304e49329377982bd6660d51",
            "09a57d02dd154bbeb0799adbc571c71c",
            "1d3862ec2d184c6c9a98290893b4e759",
            "a180660713b642c7842819c8b36f0492",
            "7dc49677476d476dbfa3263d12aa0270"
          ]
        }
      },
      "source": [
        "#@title Запустите ячейку\n",
        "#@markdown В google colab уже настроено виртуальное окружение и некоторые устанавливаемые библиотеки конфликтуют с ним. Для корректной работы необходимо после возникновения ошибки перезапустить среду выполнения (в ручную или нажать на кнопку restart runtime в логе) и запустить ячейку повторно.\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1F6X_sT3v6QdZjZLrY9DRIT-My1iUAIex' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1F6X_sT3v6QdZjZLrY9DRIT-My1iUAIex\" -O rubert_b.data-00000-of-00001 && rm -rf /tmp/cookies.txt\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1nPT3FYGReDrg5W9MbiKR007MY7v5K-xb' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1nPT3FYGReDrg5W9MbiKR007MY7v5K-xb\" -O rubert_b.meta && rm -rf /tmp/cookies.txt\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=11r60DGj6sSRGJU9yhhnm9DTwgbQrLWy5' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=11r60DGj6sSRGJU9yhhnm9DTwgbQrLWy5\" -O rubert_b.index && rm -rf /tmp/cookies.txt\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=10EY5hAfOqgPe4jvxUJBDlgex6hj0f18M' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=10EY5hAfOqgPe4jvxUJBDlgex6hj0f18M\" -O checkpoint && rm -rf /tmp/cookies.txt\n",
        "!pip install deeppavlov\n",
        "!python -m deeppavlov install rusentiment_bert\n",
        "!python -m deeppavlov download rusentiment_bert\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore') \n",
        "from IPython.display import clear_output\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import Layout, HBox\n",
        "from IPython.display import display, HTML\n",
        "from deeppavlov.models.preprocessors.bert_preprocessor import BertPreprocessor\n",
        "from deeppavlov.models.classifiers.proba2labels import Proba2Labels\n",
        "import os\n",
        "from deeppavlov.core.data.simple_vocab import SimpleVocabulary\n",
        "from deeppavlov.models.bert.bert_classifier import BertClassifierModel\n",
        "import pandas as pd\n",
        "import csv\n",
        "import re\n",
        "import numpy as np\n",
        "import copy\n",
        "from deeppavlov.dataset_iterators.basic_classification_iterator import BasicClassificationDatasetIterator\n",
        "from deeppavlov.core.data.simple_vocab import SimpleVocabulary\n",
        "from deeppavlov.models.preprocessors.one_hotter import OneHotter\n",
        " \n",
        "def predict(inp):\n",
        "    x_feat = bert_preprocessor(inp)\n",
        "    y_pred_prob = bert_classifier(x_feat)\n",
        "    y_pred = prob2labels(y_pred_prob)\n",
        "    y_pred = vocab(y_pred)\n",
        "    return y_pred[0], max(y_pred_prob[0])\n",
        " \n",
        " \n",
        " \n",
        "bert_preprocessor = BertPreprocessor(vocab_file=\"~/.deeppavlov/downloads/bert_models/multi_cased_L-12_H-768_A-12/vocab.txt\",\n",
        "                                     do_lower_case=False,\n",
        "                                     max_seq_length=256)\n",
        "prob2labels = Proba2Labels(max_proba=True)\n",
        "vocab = SimpleVocabulary(save_path=\"./binary_classes.dict\")\n",
        "vocab.fit(['true', 'fake'])\n",
        " \n",
        "one_hotter = OneHotter(depth=2, \n",
        "                       single_vector=True \n",
        "                      )\n",
        " \n",
        " \n",
        "bert_classifier = BertClassifierModel(\n",
        "    n_classes=2,\n",
        "    return_probas=True,\n",
        "    one_hot_labels=True,\n",
        "    bert_config_file='~/.deeppavlov/downloads/bert_models/multi_cased_L-12_H-768_A-12/bert_config.json',\n",
        "    pretrained_bert= '~/.deeppavlov/downloads/bert_models/multi_cased_L-12_H-768_A-12/bert_model.ckpt',\n",
        "    save_path='/content/rubert_b', \n",
        "    load_path='/content/rubert_b', \n",
        "    keep_prob=0.5,\n",
        "    learning_rate=0.1,\n",
        "    learning_rate_drop_patience=5,\n",
        "    learning_rate_drop_div=2.0\n",
        ")\n",
        " \n",
        " \n",
        "button = widgets.Button(description=\"предсказание\")\n",
        "txt_form = widgets.Text(\n",
        "    value=None,\n",
        "    placeholder='Введите новость',\n",
        "    description='',\n",
        "    disabled=False,\n",
        "    layout=Layout(width='95%', height='100%')\n",
        ")\n",
        "output = widgets.Output()\n",
        " \n",
        "def pred(value, prob):\n",
        "    return HTML(\"\"\"\n",
        "        <p>с вероятностью {prob}, эта новость {value}</p>\n",
        "    \"\"\".format(value=value, prob=prob))\n",
        " \n",
        " \n",
        "def on_button_clicked(b):\n",
        "    prediction = predict([txt_form.value]) \n",
        "    predict_html.update(pred(prediction[0], prediction[1]))\n",
        "clear_output()\n",
        "        \n",
        "button.on_click(on_button_clicked)\n",
        "display(HBox([txt_form, button]))\n",
        "predict_html = display(display_id=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "462ad225bb554ad68329f8996ee15812",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(Text(value='', layout=Layout(height='100%', width='95%'), placeholder='Введите новость'), Butto…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <p>с вероятностью 0.9866703152656555, эта новость fake</p>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCO8ms8f4-lt"
      },
      "source": [
        "# Хочу узнать как это работает\n",
        "Если вы запускали предыдущие ячейки, мы рекомендуем удалить текущий сеанс и запустить новый начиная отсюда, чтобы очистить озу и файловую систему."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NxMNaSDn6pj",
        "cellView": "form",
        "outputId": "874779dd-c688-4d3c-8b71-ddf30692ea7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        " #@title Если вы хотите подключить свой google drive\n",
        " #@markdown\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82JKwt5_cHJu",
        "cellView": "form",
        "outputId": "dd5070fc-3896-4cef-fc63-a08885376d03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#@title Установка необходимых библиотек и предобученной модели\n",
        " #@markdown Настоятельно рекомендуем перезапустить среду выполнения после установки.\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1F6X_sT3v6QdZjZLrY9DRIT-My1iUAIex' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1F6X_sT3v6QdZjZLrY9DRIT-My1iUAIex\" -O rubert_b.data-00000-of-00001 && rm -rf /tmp/cookies.txt\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1nPT3FYGReDrg5W9MbiKR007MY7v5K-xb' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1nPT3FYGReDrg5W9MbiKR007MY7v5K-xb\" -O rubert_b.meta && rm -rf /tmp/cookies.txt\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=11r60DGj6sSRGJU9yhhnm9DTwgbQrLWy5' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=11r60DGj6sSRGJU9yhhnm9DTwgbQrLWy5\" -O rubert_b.index && rm -rf /tmp/cookies.txt\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=10EY5hAfOqgPe4jvxUJBDlgex6hj0f18M' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=10EY5hAfOqgPe4jvxUJBDlgex6hj0f18M\" -O checkpoint && rm -rf /tmp/cookies.txt\n",
        " \n",
        "!pip install deeppavlov\n",
        "!python -m deeppavlov install rusentiment_bert\n",
        "!python -m deeppavlov download rusentiment_bert"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-12 12:53:49--  https://docs.google.com/uc?export=download&confirm=oGdH&id=1F6X_sT3v6QdZjZLrY9DRIT-My1iUAIex\n",
            "Resolving docs.google.com (docs.google.com)... 173.194.211.102, 173.194.211.100, 173.194.211.138, ...\n",
            "Connecting to docs.google.com (docs.google.com)|173.194.211.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0g-5g-docs.googleusercontent.com/docs/securesc/8r86f1jbrsi6ltq70cqsdtjadecuk9va/dci8bqf2opluf7lokq4irhs7lqscaue2/1602507225000/13892698310303070983/08372779740646247572Z/1F6X_sT3v6QdZjZLrY9DRIT-My1iUAIex?e=download [following]\n",
            "--2020-10-12 12:53:49--  https://doc-0g-5g-docs.googleusercontent.com/docs/securesc/8r86f1jbrsi6ltq70cqsdtjadecuk9va/dci8bqf2opluf7lokq4irhs7lqscaue2/1602507225000/13892698310303070983/08372779740646247572Z/1F6X_sT3v6QdZjZLrY9DRIT-My1iUAIex?e=download\n",
            "Resolving doc-0g-5g-docs.googleusercontent.com (doc-0g-5g-docs.googleusercontent.com)... 172.217.203.132, 2607:f8b0:400c:c07::84\n",
            "Connecting to doc-0g-5g-docs.googleusercontent.com (doc-0g-5g-docs.googleusercontent.com)|172.217.203.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://docs.google.com/nonceSigner?nonce=k9sps17j522o0&continue=https://doc-0g-5g-docs.googleusercontent.com/docs/securesc/8r86f1jbrsi6ltq70cqsdtjadecuk9va/dci8bqf2opluf7lokq4irhs7lqscaue2/1602507225000/13892698310303070983/08372779740646247572Z/1F6X_sT3v6QdZjZLrY9DRIT-My1iUAIex?e%3Ddownload&hash=557f3g822s8se9kgapl6gcv3oisv9mo9 [following]\n",
            "--2020-10-12 12:53:49--  https://docs.google.com/nonceSigner?nonce=k9sps17j522o0&continue=https://doc-0g-5g-docs.googleusercontent.com/docs/securesc/8r86f1jbrsi6ltq70cqsdtjadecuk9va/dci8bqf2opluf7lokq4irhs7lqscaue2/1602507225000/13892698310303070983/08372779740646247572Z/1F6X_sT3v6QdZjZLrY9DRIT-My1iUAIex?e%3Ddownload&hash=557f3g822s8se9kgapl6gcv3oisv9mo9\n",
            "Connecting to docs.google.com (docs.google.com)|173.194.211.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://doc-0g-5g-docs.googleusercontent.com/docs/securesc/8r86f1jbrsi6ltq70cqsdtjadecuk9va/dci8bqf2opluf7lokq4irhs7lqscaue2/1602507225000/13892698310303070983/08372779740646247572Z/1F6X_sT3v6QdZjZLrY9DRIT-My1iUAIex?e=download&nonce=k9sps17j522o0&user=08372779740646247572Z&hash=2puar49tfo5n2apq0tig1ut9me029ccf [following]\n",
            "--2020-10-12 12:53:49--  https://doc-0g-5g-docs.googleusercontent.com/docs/securesc/8r86f1jbrsi6ltq70cqsdtjadecuk9va/dci8bqf2opluf7lokq4irhs7lqscaue2/1602507225000/13892698310303070983/08372779740646247572Z/1F6X_sT3v6QdZjZLrY9DRIT-My1iUAIex?e=download&nonce=k9sps17j522o0&user=08372779740646247572Z&hash=2puar49tfo5n2apq0tig1ut9me029ccf\n",
            "Connecting to doc-0g-5g-docs.googleusercontent.com (doc-0g-5g-docs.googleusercontent.com)|172.217.203.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/octet-stream]\n",
            "Saving to: ‘rubert_b.data-00000-of-00001’\n",
            "\n",
            "rubert_b.data-00000     [     <=>            ] 678.46M  61.6MB/s    in 9.8s    \n",
            "\n",
            "2020-10-12 12:54:00 (69.2 MB/s) - ‘rubert_b.data-00000-of-00001’ saved [711419920]\n",
            "\n",
            "--2020-10-12 12:54:01--  https://docs.google.com/uc?export=download&confirm=&id=1nPT3FYGReDrg5W9MbiKR007MY7v5K-xb\n",
            "Resolving docs.google.com (docs.google.com)... 173.194.216.100, 173.194.216.138, 173.194.216.102, ...\n",
            "Connecting to docs.google.com (docs.google.com)|173.194.216.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-10-14-docs.googleusercontent.com/docs/securesc/50acdv4ajjgkf4v0e4st4ro16ufpuutc/bgmggolr8ic59ij857guss3h5od6kscr/1602507225000/13892698310303070983/06169344211118573123Z/1nPT3FYGReDrg5W9MbiKR007MY7v5K-xb?e=download [following]\n",
            "--2020-10-12 12:54:02--  https://doc-10-14-docs.googleusercontent.com/docs/securesc/50acdv4ajjgkf4v0e4st4ro16ufpuutc/bgmggolr8ic59ij857guss3h5od6kscr/1602507225000/13892698310303070983/06169344211118573123Z/1nPT3FYGReDrg5W9MbiKR007MY7v5K-xb?e=download\n",
            "Resolving doc-10-14-docs.googleusercontent.com (doc-10-14-docs.googleusercontent.com)... 172.217.203.132, 2607:f8b0:400c:c07::84\n",
            "Connecting to doc-10-14-docs.googleusercontent.com (doc-10-14-docs.googleusercontent.com)|172.217.203.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://docs.google.com/nonceSigner?nonce=4t0f6sbsap3ck&continue=https://doc-10-14-docs.googleusercontent.com/docs/securesc/50acdv4ajjgkf4v0e4st4ro16ufpuutc/bgmggolr8ic59ij857guss3h5od6kscr/1602507225000/13892698310303070983/06169344211118573123Z/1nPT3FYGReDrg5W9MbiKR007MY7v5K-xb?e%3Ddownload&hash=v9sbpuq93a7ulj9bqkbh07nt1l3klhho [following]\n",
            "--2020-10-12 12:54:02--  https://docs.google.com/nonceSigner?nonce=4t0f6sbsap3ck&continue=https://doc-10-14-docs.googleusercontent.com/docs/securesc/50acdv4ajjgkf4v0e4st4ro16ufpuutc/bgmggolr8ic59ij857guss3h5od6kscr/1602507225000/13892698310303070983/06169344211118573123Z/1nPT3FYGReDrg5W9MbiKR007MY7v5K-xb?e%3Ddownload&hash=v9sbpuq93a7ulj9bqkbh07nt1l3klhho\n",
            "Connecting to docs.google.com (docs.google.com)|173.194.216.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://doc-10-14-docs.googleusercontent.com/docs/securesc/50acdv4ajjgkf4v0e4st4ro16ufpuutc/bgmggolr8ic59ij857guss3h5od6kscr/1602507225000/13892698310303070983/06169344211118573123Z/1nPT3FYGReDrg5W9MbiKR007MY7v5K-xb?e=download&nonce=4t0f6sbsap3ck&user=06169344211118573123Z&hash=8pqma83b2hj6bvfvbo29rnrdv45minub [following]\n",
            "--2020-10-12 12:54:02--  https://doc-10-14-docs.googleusercontent.com/docs/securesc/50acdv4ajjgkf4v0e4st4ro16ufpuutc/bgmggolr8ic59ij857guss3h5od6kscr/1602507225000/13892698310303070983/06169344211118573123Z/1nPT3FYGReDrg5W9MbiKR007MY7v5K-xb?e=download&nonce=4t0f6sbsap3ck&user=06169344211118573123Z&hash=8pqma83b2hj6bvfvbo29rnrdv45minub\n",
            "Connecting to doc-10-14-docs.googleusercontent.com (doc-10-14-docs.googleusercontent.com)|172.217.203.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/octet-stream]\n",
            "Saving to: ‘rubert_b.meta’\n",
            "\n",
            "rubert_b.meta           [ <=>                ]   5.71M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2020-10-12 12:54:02 (104 MB/s) - ‘rubert_b.meta’ saved [5989810]\n",
            "\n",
            "--2020-10-12 12:54:03--  https://docs.google.com/uc?export=download&confirm=&id=11r60DGj6sSRGJU9yhhnm9DTwgbQrLWy5\n",
            "Resolving docs.google.com (docs.google.com)... 172.217.204.100, 172.217.204.139, 172.217.204.101, ...\n",
            "Connecting to docs.google.com (docs.google.com)|172.217.204.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0o-8k-docs.googleusercontent.com/docs/securesc/a3gccgb90uih3otcbotjqbqs454nq5k3/hu9uvnpgl83g30oa9kn5ucekb7au6m6a/1602507225000/13892698310303070983/17379762762332485504Z/11r60DGj6sSRGJU9yhhnm9DTwgbQrLWy5?e=download [following]\n",
            "--2020-10-12 12:54:03--  https://doc-0o-8k-docs.googleusercontent.com/docs/securesc/a3gccgb90uih3otcbotjqbqs454nq5k3/hu9uvnpgl83g30oa9kn5ucekb7au6m6a/1602507225000/13892698310303070983/17379762762332485504Z/11r60DGj6sSRGJU9yhhnm9DTwgbQrLWy5?e=download\n",
            "Resolving doc-0o-8k-docs.googleusercontent.com (doc-0o-8k-docs.googleusercontent.com)... 172.217.203.132, 2607:f8b0:400c:c07::84\n",
            "Connecting to doc-0o-8k-docs.googleusercontent.com (doc-0o-8k-docs.googleusercontent.com)|172.217.203.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://docs.google.com/nonceSigner?nonce=lionbnkfduus4&continue=https://doc-0o-8k-docs.googleusercontent.com/docs/securesc/a3gccgb90uih3otcbotjqbqs454nq5k3/hu9uvnpgl83g30oa9kn5ucekb7au6m6a/1602507225000/13892698310303070983/17379762762332485504Z/11r60DGj6sSRGJU9yhhnm9DTwgbQrLWy5?e%3Ddownload&hash=8qiurtneuhffthadjikqr6g9q1o1ti77 [following]\n",
            "--2020-10-12 12:54:03--  https://docs.google.com/nonceSigner?nonce=lionbnkfduus4&continue=https://doc-0o-8k-docs.googleusercontent.com/docs/securesc/a3gccgb90uih3otcbotjqbqs454nq5k3/hu9uvnpgl83g30oa9kn5ucekb7au6m6a/1602507225000/13892698310303070983/17379762762332485504Z/11r60DGj6sSRGJU9yhhnm9DTwgbQrLWy5?e%3Ddownload&hash=8qiurtneuhffthadjikqr6g9q1o1ti77\n",
            "Connecting to docs.google.com (docs.google.com)|172.217.204.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://doc-0o-8k-docs.googleusercontent.com/docs/securesc/a3gccgb90uih3otcbotjqbqs454nq5k3/hu9uvnpgl83g30oa9kn5ucekb7au6m6a/1602507225000/13892698310303070983/17379762762332485504Z/11r60DGj6sSRGJU9yhhnm9DTwgbQrLWy5?e=download&nonce=lionbnkfduus4&user=17379762762332485504Z&hash=2c4q2pun5sc5kc1mqp1mms02o5asr60l [following]\n",
            "--2020-10-12 12:54:03--  https://doc-0o-8k-docs.googleusercontent.com/docs/securesc/a3gccgb90uih3otcbotjqbqs454nq5k3/hu9uvnpgl83g30oa9kn5ucekb7au6m6a/1602507225000/13892698310303070983/17379762762332485504Z/11r60DGj6sSRGJU9yhhnm9DTwgbQrLWy5?e=download&nonce=lionbnkfduus4&user=17379762762332485504Z&hash=2c4q2pun5sc5kc1mqp1mms02o5asr60l\n",
            "Connecting to doc-0o-8k-docs.googleusercontent.com (doc-0o-8k-docs.googleusercontent.com)|172.217.203.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8464 (8.3K) [application/octet-stream]\n",
            "Saving to: ‘rubert_b.index’\n",
            "\n",
            "rubert_b.index      100%[===================>]   8.27K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-10-12 12:54:03 (57.8 MB/s) - ‘rubert_b.index’ saved [8464/8464]\n",
            "\n",
            "--2020-10-12 12:54:03--  https://docs.google.com/uc?export=download&confirm=&id=10EY5hAfOqgPe4jvxUJBDlgex6hj0f18M\n",
            "Resolving docs.google.com (docs.google.com)... 172.217.204.138, 172.217.204.100, 172.217.204.102, ...\n",
            "Connecting to docs.google.com (docs.google.com)|172.217.204.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-10-5c-docs.googleusercontent.com/docs/securesc/49e3fg516hdq543i9redgu2e1tthfelg/skp90bau2far5adslbqncf5cji67kcfu/1602507225000/13892698310303070983/07199387656873900875Z/10EY5hAfOqgPe4jvxUJBDlgex6hj0f18M?e=download [following]\n",
            "--2020-10-12 12:54:04--  https://doc-10-5c-docs.googleusercontent.com/docs/securesc/49e3fg516hdq543i9redgu2e1tthfelg/skp90bau2far5adslbqncf5cji67kcfu/1602507225000/13892698310303070983/07199387656873900875Z/10EY5hAfOqgPe4jvxUJBDlgex6hj0f18M?e=download\n",
            "Resolving doc-10-5c-docs.googleusercontent.com (doc-10-5c-docs.googleusercontent.com)... 172.217.203.132, 2607:f8b0:400c:c07::84\n",
            "Connecting to doc-10-5c-docs.googleusercontent.com (doc-10-5c-docs.googleusercontent.com)|172.217.203.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://docs.google.com/nonceSigner?nonce=2g09k9i4grd40&continue=https://doc-10-5c-docs.googleusercontent.com/docs/securesc/49e3fg516hdq543i9redgu2e1tthfelg/skp90bau2far5adslbqncf5cji67kcfu/1602507225000/13892698310303070983/07199387656873900875Z/10EY5hAfOqgPe4jvxUJBDlgex6hj0f18M?e%3Ddownload&hash=8fdupa0f8hc4e18quvm7ei8op79892bq [following]\n",
            "--2020-10-12 12:54:04--  https://docs.google.com/nonceSigner?nonce=2g09k9i4grd40&continue=https://doc-10-5c-docs.googleusercontent.com/docs/securesc/49e3fg516hdq543i9redgu2e1tthfelg/skp90bau2far5adslbqncf5cji67kcfu/1602507225000/13892698310303070983/07199387656873900875Z/10EY5hAfOqgPe4jvxUJBDlgex6hj0f18M?e%3Ddownload&hash=8fdupa0f8hc4e18quvm7ei8op79892bq\n",
            "Connecting to docs.google.com (docs.google.com)|172.217.204.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://doc-10-5c-docs.googleusercontent.com/docs/securesc/49e3fg516hdq543i9redgu2e1tthfelg/skp90bau2far5adslbqncf5cji67kcfu/1602507225000/13892698310303070983/07199387656873900875Z/10EY5hAfOqgPe4jvxUJBDlgex6hj0f18M?e=download&nonce=2g09k9i4grd40&user=07199387656873900875Z&hash=lqpa0ms1ne66q4baf1c49b89ovi8fhee [following]\n",
            "--2020-10-12 12:54:04--  https://doc-10-5c-docs.googleusercontent.com/docs/securesc/49e3fg516hdq543i9redgu2e1tthfelg/skp90bau2far5adslbqncf5cji67kcfu/1602507225000/13892698310303070983/07199387656873900875Z/10EY5hAfOqgPe4jvxUJBDlgex6hj0f18M?e=download&nonce=2g09k9i4grd40&user=07199387656873900875Z&hash=lqpa0ms1ne66q4baf1c49b89ovi8fhee\n",
            "Connecting to doc-10-5c-docs.googleusercontent.com (doc-10-5c-docs.googleusercontent.com)|172.217.203.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 139 [application/octet-stream]\n",
            "Saving to: ‘checkpoint’\n",
            "\n",
            "checkpoint          100%[===================>]     139  --.-KB/s    in 0s      \n",
            "\n",
            "2020-10-12 12:54:04 (6.42 MB/s) - ‘checkpoint’ saved [139/139]\n",
            "\n",
            "Collecting deeppavlov\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6d/f6/df4ce4c5c5cafd8d357a4c02cb1ccb5ff1d8f3c21de3e5d02299eef56342/deeppavlov-0.12.1-py3-none-any.whl (948kB)\n",
            "\u001b[K     |████████████████████████████████| 952kB 2.8MB/s \n",
            "\u001b[?25hCollecting pymorphy2==0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.3MB/s \n",
            "\u001b[?25hCollecting pymorphy2-dicts-ru\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/79/bea0021eeb7eeefde22ef9e96badf174068a2dd20264b9a378f2be1cdd9e/pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2MB 14.6MB/s \n",
            "\u001b[?25hCollecting fastapi==0.47.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/a7/4804d7abf8a1544d079d50650af872387154ebdac5bd07d54b2e60e2b334/fastapi-0.47.1-py3-none-any.whl (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.0MB/s \n",
            "\u001b[?25hCollecting requests==2.22.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.2MB/s \n",
            "\u001b[?25hCollecting pandas==0.25.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/3f/f6a428599e0d4497e1595030965b5ba455fd8ade6e977e3c819973c4b41d/pandas-0.25.3-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4MB 47.9MB/s \n",
            "\u001b[?25hCollecting nltk==3.4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 24.0MB/s \n",
            "\u001b[?25hCollecting numpy==1.18.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/e6/45f71bd24f4e37629e9db5fb75caab919507deae6a5a257f9e4685a5f931/numpy-1.18.0-cp36-cp36m-manylinux1_x86_64.whl (20.1MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1MB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm==4.41.1 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (4.41.1)\n",
            "Requirement already satisfied: click==7.1.2 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (7.1.2)\n",
            "Collecting aio-pika==6.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/07/196a4115cbef31fa0c3dabdea146f02dffe5e49998341d20dbe2278953bc/aio_pika-6.4.1-py3-none-any.whl (40kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (1.4.1)\n",
            "Collecting pytz==2019.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/73/fe30c2daaaa0713420d0382b16fbb761409f532c56bdcc514bf7b6262bb6/pytz-2019.1-py2.py3-none-any.whl (510kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 40.1MB/s \n",
            "\u001b[?25hCollecting uvicorn==0.11.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/5f/2bc87272f189662e129ddcd4807ad3ef83128b4df3a3482335f5f9790f24/uvicorn-0.11.7-py3-none-any.whl (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.5MB/s \n",
            "\u001b[?25hCollecting rusenttokenize==0.0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/25/4c/a2f00be5def774a3df2e5387145f1cb54e324607ec4a7e23f573645946e7/rusenttokenize-0.0.5-py3-none-any.whl\n",
            "Requirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (2.10.0)\n",
            "Collecting scikit-learn==0.21.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/04/49633f490f726da6e454fddc8e938bbb5bfed2001681118d3814c219b723/scikit_learn-0.21.2-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 44.6MB/s \n",
            "\u001b[?25hCollecting ruamel.yaml==0.15.100\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/9f/83bb34eaf84032b0b54fcc4a6aff1858572d279d65a301c7ae875f523df5/ruamel.yaml-0.15.100-cp36-cp36m-manylinux1_x86_64.whl (656kB)\n",
            "\u001b[K     |████████████████████████████████| 665kB 42.5MB/s \n",
            "\u001b[?25hCollecting overrides==2.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ac/98/2430afd204c48ac0a529d439d7e22df8fa603c668d03456b5947cb59ec36/overrides-2.7.0.tar.gz\n",
            "Collecting pyopenssl==19.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/de/f8342b68fa9e981d348039954657bdf681b2ab93de27443be51865ffa310/pyOpenSSL-19.1.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.8MB/s \n",
            "\u001b[?25hCollecting Cython==0.29.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/df/d1/4d3f8a7a920e805488a966cc6ab55c978a712240f584445d703c08b9f405/Cython-0.29.14-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 36.0MB/s \n",
            "\u001b[?25hCollecting pytelegrambotapi==3.6.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/ab/99c606f69fcda57e35788b913dd34c9d9acb48dd26349141b3855dcf6351/pyTelegramBotAPI-3.6.7.tar.gz (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.6MB/s \n",
            "\u001b[?25hCollecting pydantic==1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/24/e78cf017628e7eaed20cb040999b1ecc69f872da53dfd0d9aed40c0fa5f1/pydantic-1.3-cp36-cp36m-manylinux2010_x86_64.whl (7.3MB)\n",
            "\u001b[K     |████████████████████████████████| 7.3MB 11.3MB/s \n",
            "\u001b[?25hCollecting sacremoses==0.0.35\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n",
            "\u001b[K     |████████████████████████████████| 860kB 41.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2==0.8->deeppavlov) (0.6.2)\n",
            "Collecting pymorphy2-dicts<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 25.9MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Collecting starlette<=0.12.9,>=0.12.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/95/2220fe5bf287e693a6430d8ee36c681b0157035b7249ec08f8fb36319d16/starlette-0.12.9.tar.gz (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.0MB/s \n",
            "\u001b[?25hCollecting idna<2.9,>=2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas==0.25.3->deeppavlov) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk==3.4.5->deeppavlov) (1.15.0)\n",
            "Collecting aiormq<4,>=3.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/6b/c6/4a9f8f22eef268289e9af5da6a620d837c700b333eae01132bfe48fe7dc9/aiormq-3.2.3-py3-none-any.whl\n",
            "Collecting yarl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/01/c9/379b807a9c298b9694d0af8ee4260be7d40ab1a11fb9d4ae9e70b1e69d96/yarl-1.6.0-cp36-cp36m-manylinux1_x86_64.whl (257kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 48.9MB/s \n",
            "\u001b[?25hCollecting uvloop>=0.14.0; sys_platform != \"win32\" and sys_platform != \"cygwin\" and platform_python_implementation != \"PyPy\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/48/586225bbb02d3bdca475b17e4be5ce5b3f09da2d6979f359916c1592a687/uvloop-0.14.0-cp36-cp36m-manylinux2010_x86_64.whl (3.9MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 43.3MB/s \n",
            "\u001b[?25hCollecting websockets==8.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/d9/856af84843912e2853b1b6e898ac8b802989fcf9ecf8e8445a1da263bf3b/websockets-8.1-cp36-cp36m-manylinux2010_x86_64.whl (78kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.0MB/s \n",
            "\u001b[?25hCollecting h11<0.10,>=0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/fd/3dad730b0f95e78aeeb742f96fa7bbecbdd56a58e405d3da440d5bfb90c6/h11-0.9.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.6MB/s \n",
            "\u001b[?25hCollecting httptools==0.1.*; sys_platform != \"win32\" and sys_platform != \"cygwin\" and platform_python_implementation != \"PyPy\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/a6/dc1e7e8f4049ab70d52c9690ec10652e268ab2542853033cc1d539594102/httptools-0.1.1-cp36-cp36m-manylinux1_x86_64.whl (216kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 50.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.21.2->deeppavlov) (0.16.0)\n",
            "Collecting cryptography>=2.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/62/30f6936941d87a5ed72efb24249437824f6b2c953901245b58c91fde2f27/cryptography-3.1.1-cp35-abi3-manylinux2010_x86_64.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 40.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses>=0.6; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from pydantic==1.3->deeppavlov) (0.7)\n",
            "Collecting pamqp==2.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/56/afa06143361e640c9159d828dadc95fc9195c52c95b4a97d136617b0166d/pamqp-2.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: typing-extensions>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from yarl->aio-pika==6.4.1->deeppavlov) (3.7.4.3)\n",
            "Collecting multidict>=4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/78/a0/7c0f5bf1bdcfe88da60d13ba1fead20cb960ae11a355adafae59907d9ae1/multidict-5.0.0-cp36-cp36m-manylinux2014_x86_64.whl (141kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 49.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.8->pyopenssl==19.1.0->deeppavlov) (1.14.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.8->pyopenssl==19.1.0->deeppavlov) (2.20)\n",
            "Building wheels for collected packages: nltk, overrides, pytelegrambotapi, sacremoses, starlette\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-cp36-none-any.whl size=1449904 sha256=494e0aff210376e2d9203cb7ff8ae3b580dd5c77a13cc0bcab4b9529a7a3b380\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-2.7.0-cp36-none-any.whl size=5601 sha256=e7490bded8c26214bcd3dacd0ecf78ec07a9a809a58cae8a9573df7d7b863e0d\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/7c/ef/80508418b67d87371c5b3de49e03eb22ee7c1d19affb5099f8\n",
            "  Building wheel for pytelegrambotapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytelegrambotapi: filename=pyTelegramBotAPI-3.6.7-cp36-none-any.whl size=47179 sha256=59f315bce1236cf880f1824811620c3d4dcb5657d981dae3a92c71a526a9181d\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/40/18/8a34153f95ef0dc19e3954898e5a5079244b76a8afdd7d0ec5\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=2e08fee84f4fa59c30c54dc1ca02e87c039ebe3598146c42bf005d6eccdaa790\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n",
            "  Building wheel for starlette (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for starlette: filename=starlette-0.12.9-cp36-none-any.whl size=57245 sha256=86049799acab770076ab0b46d287135689329db8171a27c0c29b9326f46eb53e\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/51/5b/3828d52e185cafad941c4291b6f70894d0794be28c70addae5\n",
            "Successfully built nltk overrides pytelegrambotapi sacremoses starlette\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement pandas>=1.0.4, but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pymorphy2-dicts, dawg-python, pymorphy2, pymorphy2-dicts-ru, starlette, pydantic, fastapi, idna, requests, numpy, pytz, pandas, nltk, pamqp, multidict, yarl, aiormq, aio-pika, uvloop, websockets, h11, httptools, uvicorn, rusenttokenize, scikit-learn, ruamel.yaml, overrides, cryptography, pyopenssl, Cython, pytelegrambotapi, sacremoses, deeppavlov\n",
            "  Found existing installation: idna 2.10\n",
            "    Uninstalling idna-2.10:\n",
            "      Successfully uninstalled idna-2.10\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: numpy 1.18.5\n",
            "    Uninstalling numpy-1.18.5:\n",
            "      Successfully uninstalled numpy-1.18.5\n",
            "  Found existing installation: pytz 2018.9\n",
            "    Uninstalling pytz-2018.9:\n",
            "      Successfully uninstalled pytz-2018.9\n",
            "  Found existing installation: pandas 1.1.2\n",
            "    Uninstalling pandas-1.1.2:\n",
            "      Successfully uninstalled pandas-1.1.2\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Found existing installation: Cython 0.29.21\n",
            "    Uninstalling Cython-0.29.21:\n",
            "      Successfully uninstalled Cython-0.29.21\n",
            "Successfully installed Cython-0.29.14 aio-pika-6.4.1 aiormq-3.2.3 cryptography-3.1.1 dawg-python-0.7.2 deeppavlov-0.12.1 fastapi-0.47.1 h11-0.9.0 httptools-0.1.1 idna-2.8 multidict-5.0.0 nltk-3.4.5 numpy-1.18.0 overrides-2.7.0 pamqp-2.3.0 pandas-0.25.3 pydantic-1.3 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985 pymorphy2-dicts-ru-2.4.417127.4579844 pyopenssl-19.1.0 pytelegrambotapi-3.6.7 pytz-2019.1 requests-2.22.0 ruamel.yaml-0.15.100 rusenttokenize-0.0.5 sacremoses-0.0.35 scikit-learn-0.21.2 starlette-0.12.9 uvicorn-0.11.7 uvloop-0.14.0 websockets-8.1 yarl-1.6.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pandas",
                  "pytz"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-12 12:54:53.734 INFO in 'deeppavlov.core.common.file'['file'] at line 32: Interpreting 'rusentiment_bert' as '/usr/local/lib/python3.6/dist-packages/deeppavlov/configs/classifiers/rusentiment_bert.json'\n",
            "Collecting tensorflow==1.15.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/d9/fd234c7bf68638423fb8e7f44af7fcfce3bcaf416b51e6d902391e47ec43/tensorflow-1.15.2-cp36-cp36m-manylinux2010_x86_64.whl (110.5MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5MB 46kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (3.12.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.15.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.9MB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.35.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.10.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 39.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.18.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.12.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.2.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.8.1)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 39.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.32.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15.2) (50.3.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.2) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.2.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7542 sha256=4df97d84f407e075f0a7858bf0961b825bc445d3c4640bcd8b50e7c66cac5cb1\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras-applications, gast, tensorflow-estimator, tensorboard, tensorflow\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.2 tensorflow-estimator-1.15.1\n",
            "Collecting git+https://github.com/deepmipt/bert.git@feat/multi_gpu\n",
            "  Cloning https://github.com/deepmipt/bert.git (to revision feat/multi_gpu) to /tmp/pip-req-build-5cv2edmc\n",
            "  Running command git clone -q https://github.com/deepmipt/bert.git /tmp/pip-req-build-5cv2edmc\n",
            "Building wheels for collected packages: bert-dp\n",
            "  Building wheel for bert-dp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-dp: filename=bert_dp-1.0-cp36-none-any.whl size=23581 sha256=a7cb5271e200ad74d02e9b18c42d841675731663cc68f1774195328b37aa81a0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ew03cyfm/wheels/1e/41/94/886107eaf932532594886fd8bfc9cb9d4db632e94add49d326\n",
            "Successfully built bert-dp\n",
            "Installing collected packages: bert-dp\n",
            "Successfully installed bert-dp-1.0\n",
            "2020-10-12 12:55:44.431 INFO in 'deeppavlov.core.common.file'['file'] at line 32: Interpreting 'rusentiment_bert' as '/usr/local/lib/python3.6/dist-packages/deeppavlov/configs/classifiers/rusentiment_bert.json'\n",
            "2020-10-12 12:55:44.914 INFO in 'deeppavlov.core.data.utils'['utils'] at line 94: Downloading from http://files.deeppavlov.ai/deeppavlov_data/bert/multi_cased_L-12_H-768_A-12.zip?config=rusentiment_bert to /root/.deeppavlov/downloads/multi_cased_L-12_H-768_A-12.zip\n",
            "100% 663M/663M [03:40<00:00, 3.01MB/s]\n",
            "2020-10-12 12:59:25.456 INFO in 'deeppavlov.core.data.utils'['utils'] at line 269: Extracting /root/.deeppavlov/downloads/multi_cased_L-12_H-768_A-12.zip archive into /root/.deeppavlov/downloads/bert_models\n",
            "2020-10-12 12:59:32.952 INFO in 'deeppavlov.core.data.utils'['utils'] at line 94: Downloading from http://files.deeppavlov.ai/deeppavlov_data/classifiers/rusentiment_bert_v0.tar.gz?config=rusentiment_bert to /root/.deeppavlov/models/rusentiment_bert_v0.tar.gz\n",
            "100% 1.32G/1.32G [05:54<00:00, 3.72MB/s]\n",
            "2020-10-12 13:05:27.770 INFO in 'deeppavlov.core.data.utils'['utils'] at line 269: Extracting /root/.deeppavlov/models/rusentiment_bert_v0.tar.gz archive into /root/.deeppavlov/models/classifiers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEcDN1LLrmtH"
      },
      "source": [
        "## Создание препроцессора для обработки естественного языка и объявление модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHzWodEgcHJ7",
        "cellView": "form",
        "outputId": "7373a4f3-b47c-43f0-cf22-3dddb1b07d90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "#@title Ограничение длины предложения.\n",
        " #@markdown В силу ограниченных вычислительных ресурсов и особенностей реализации, мы вынуждены нормировать длину текста\n",
        "from deeppavlov.models.preprocessors.bert_preprocessor import BertPreprocessor\n",
        "from deeppavlov.models.classifiers.proba2labels import Proba2Labels\n",
        "MAX_LEN =  256#@param {type:\"raw\"}\n",
        "bert_preprocessor = BertPreprocessor(vocab_file=\"~/.deeppavlov/downloads/bert_models/multi_cased_L-12_H-768_A-12/vocab.txt\",\n",
        "                                     do_lower_case=False,\n",
        "                                     max_seq_length=MAX_LEN)\n",
        "prob2labels = Proba2Labels(max_proba=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Package perluniprops is already up-to-date!\n",
            "[nltk_data] Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_dp/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9R8dUpKHEgE",
        "cellView": "form",
        "outputId": "01838684-bdcb-4c4c-c478-5be711302406",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "#@title Демонстрация работы препроцессора\n",
        "#@markdown Введите текст и запустите ячейку \n",
        "inp = '\\u0417\\u0430\\u0441\\u043B\\u0443\\u0436\\u0435\\u043D\\u043D\\u044B\\u0439 \\u0432\\u0440\\u0430\\u0447, \\u043F\\u0440\\u0435\\u0437\\u0438\\u0434\\u0435\\u043D\\u0442 \\u0420\\u043E\\u0441\\u0441\\u0438\\u0439\\u0441\\u043A\\u043E\\u0433\\u043E \\u043E\\u0431\\u0449\\u0435\\u0441\\u0442\\u0432\\u0430 \\u0441\\u043E\\u043C\\u043D\\u043E\\u043B\\u043E\\u0433\\u043E\\u0432 \\u0420\\u043E\\u043C\\u0430\\u043D \\u0411\\u0443\\u0437\\u0443\\u043D\\u043E\\u0432 \\u0432 \\u0438\\u043D\\u0442\\u0435\\u0440\\u0432\\u044C\\u044E \\u041F\\u044F\\u0442\\u043E\\u043C\\u0443 \\u043A\\u0430\\u043D\\u0430\\u043B\\u0443 \\u043F\\u0435\\u0440\\u0435\\u0447\\u0438\\u0441\\u043B\\u0438\\u043B \\u0440\\u0430\\u0441\\u043F\\u0440\\u043E\\u0441\\u0442\\u0440\\u0430\\u043D\\u0435\\u043D\\u043D\\u044B\\u0435, \\u043D\\u043E \\u043D\\u0435\\u043E\\u0447\\u0435\\u0432\\u0438\\u0434\\u043D\\u044B\\u0435 \\u043F\\u0440\\u0438\\u0447\\u0438\\u043D\\u044B \\u0434\\u043D\\u0435\\u0432\\u043D\\u043E\\u0439 \\u0441\\u043E\\u043D\\u043B\\u0438\\u0432\\u043E\\u0441\\u0442\\u0438. \\u0423\\u0442\\u043E\\u0447\\u043D\\u044F\\u0435\\u0442\\u0441\\u044F, \\u0447\\u0442\\u043E \\u0440\\u0435\\u0447\\u044C \\u0438\\u0434\\u0435\\u0442 \\u043E \\u0441\\u0438\\u0442\\u0443\\u0430\\u0446\\u0438\\u0438, \\u043A\\u043E\\u0433\\u0434\\u0430 \\u0445\\u043E\\u0447\\u0435\\u0442\\u0441\\u044F \\u0441\\u043F\\u0430\\u0442\\u044C \\u0434\\u0430\\u0436\\u0435 \\u043F\\u043E\\u0441\\u043B\\u0435 \\u043F\\u043E\\u043B\\u043D\\u043E\\u0446\\u0435\\u043D\\u043D\\u043E\\u0433\\u043E \\u0432\\u043E\\u0441\\u044C\\u043C\\u0438\\u0447\\u0430\\u0441\\u043E\\u0432\\u043E\\u0433\\u043E \\u043D\\u043E\\u0447\\u043D\\u043E\\u0433\\u043E \\u043E\\u0442\\u0434\\u044B\\u0445\\u0430. \\u0422\\u0430\\u043A\\u043E\\u0435 \\u0441\\u043E\\u0441\\u0442\\u043E\\u044F\\u043D\\u0438\\u0435 \\u0441\\u043F\\u0435\\u0446\\u0438\\u0430\\u043B\\u0438\\u0441\\u0442\\u044B \\u043D\\u0430\\u0437\\u044B\\u0432\\u0430\\u044E\\u0442 \\u0433\\u0438\\u043F\\u0435\\u0440\\u0441\\u043E\\u043C\\u043D\\u0438\\u0435\\u0439.'  #@param {type:\"string\"}\n",
        "input_features = bert_preprocessor([inp])\n",
        "print('обработанные данные, которые попадут в модель') \n",
        "print(input_features[0].tokens)\n",
        "print(input_features[0].input_ids)\n",
        "print(input_features[0].input_mask)\n",
        "print(input_features[0].input_type_ids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "обработанные данные, которые попадут в модель\n",
            "['[CLS]', 'Заслуженный', 'врач', ',', 'президент', 'Р', '##ос', '##сийского', 'общества', 'со', '##мно', '##лого', '##в', 'Роман', 'Бу', '##зу', '##нов', 'в', 'интервью', 'П', '##ято', '##му', 'канал', '##у', 'пер', '##ечи', '##сли', '##л', 'р', '##ас', '##прос', '##тра', '##нен', '##ные', ',', 'но', 'не', '##оче', '##вид', '##ные', 'причин', '##ы', 'д', '##не', '##вной', 'со', '##н', '##ливо', '##сти', '.', 'У', '##то', '##ч', '##няется', ',', 'что', 'р', '##ечь', 'и', '##дет', 'о', 'ситуации', ',', 'когда', 'х', '##очет', '##ся', 'с', '##пат', '##ь', 'даже', 'после', 'пол', '##но', '##цен', '##ного', 'восьми', '##час', '##ового', 'но', '##чного', 'от', '##ды', '##ха', '.', 'Тако', '##е', 'состояние', 'с', '##пециалист', '##ы', 'называют', 'ги', '##пер', '##сом', '##ние', '##й', '.', '[SEP]']\n",
            "[101, 51262, 95739, 117, 27419, 525, 17969, 72457, 27089, 10956, 107960, 54270, 10541, 36314, 81478, 19692, 18383, 543, 64553, 524, 73585, 11805, 41308, 10227, 61381, 94218, 34509, 10517, 557, 18291, 99842, 29672, 23045, 11194, 117, 11279, 10375, 67741, 53156, 11194, 32357, 10292, 545, 10695, 43170, 10956, 10267, 49256, 12189, 119, 528, 10752, 11746, 54227, 117, 10791, 557, 75865, 549, 82635, 555, 81329, 117, 15283, 562, 110732, 10625, 558, 70588, 10851, 21769, 11921, 23750, 10636, 88361, 11050, 100815, 45046, 18248, 11279, 18088, 10332, 11890, 16183, 119, 105143, 10205, 76266, 558, 97516, 10292, 61692, 15649, 29633, 33412, 13541, 10384, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgGTTfgqcHKo",
        "cellView": "form",
        "outputId": "9b806385-e0b7-4ddc-dc3e-a53cc15798a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        }
      },
      "source": [
        "#@title Создание модели BERT\n",
        "#@markdown на обучение новой модели может потребоваться несколько дней\n",
        "import os\n",
        "from deeppavlov.core.data.simple_vocab import SimpleVocabulary\n",
        "from deeppavlov.models.bert.bert_classifier import BertClassifierModel\n",
        "mode = \"\\u0438\\u0441\\u043F\\u043E\\u043B\\u044C\\u0437\\u043E\\u0432\\u0430\\u0442\\u044C \\u0433\\u043E\\u0442\\u043E\\u0432\\u0443\\u044E\" #@param [\"\\u0438\\u0441\\u043F\\u043E\\u043B\\u044C\\u0437\\u043E\\u0432\\u0430\\u0442\\u044C \\u0433\\u043E\\u0442\\u043E\\u0432\\u0443\\u044E\", \"\\u0441\\u043E\\u0437\\u0434\\u0430\\u0442\\u044C \\u043D\\u043E\\u0432\\u0443\\u044E\"]\n",
        "if mode == '\\u0438\\u0441\\u043F\\u043E\\u043B\\u044C\\u0437\\u043E\\u0432\\u0430\\u0442\\u044C \\u0433\\u043E\\u0442\\u043E\\u0432\\u0443\\u044E':\n",
        "    out_print = 'используется готовая модель'\n",
        "    config_file = '~/.deeppavlov/downloads/bert_models/multi_cased_L-12_H-768_A-12/bert_config.json' \n",
        "    pretrained_bert = '~/.deeppavlov/downloads/bert_models/multi_cased_L-12_H-768_A-12/bert_model.ckpt' \n",
        "    save_path = '/content/rubert_b' \n",
        "    load_path = '/content/rubert_b' \n",
        "else:\n",
        "    out_print = 'вы не ищете легких путей'\n",
        "    config_file = '~/.deeppavlov/downloads/bert_models/multi_cased_L-12_H-768_A-12/bert_config.json' \n",
        "    pretrained_bert = '~/.deeppavlov/downloads/bert_models/multi_cased_L-12_H-768_A-12/bert_model.ckpt' \n",
        "    save_path = '/content/drive/My Drive/test_bert/model' \n",
        "    load_path = '/content/drive/My Drive/test_bert/model' \n",
        "#@markdown внимание изменять следующие переменные необходимо лишь при условии, что вы знаете что делаете\n",
        "config_file = config_file #@param {type:\"string\"}\n",
        "pretrained_bert = pretrained_bert #@param {type:\"string\"}\n",
        "save_path =  save_path#@param {type:\"string\"}\n",
        "load_path = load_path #@param {type:\"string\"}\n",
        "learning_rate = 0.00001 #@param {type:\"slider\", min:0.00001, max:0.001, step:0.00001}\n",
        "n_classes=2#@param {type:\"slider\", min:1, max:100, step:1}\n",
        " \n",
        "bert_classifier = BertClassifierModel(\n",
        "    n_classes=n_classes,\n",
        "    return_probas=True,\n",
        "    one_hot_labels=True,\n",
        "    bert_config_file=config_file,\n",
        "    pretrained_bert=pretrained_bert,#~/.deeppavlov/downloads/bert_models/multi_cased_L-12_H-768_A-12/bert_model.ckpt\n",
        "    save_path=save_path, \n",
        "    load_path=load_path, \n",
        "    keep_prob=0.5,\n",
        "    learning_rate=learning_rate,\n",
        "    learning_rate_drop_patience=5,\n",
        "    learning_rate_drop_div=2.0\n",
        ")\n",
        "print(out_print)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:37: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:193: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/bert/bert_classifier.py:84: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/bert/bert_classifier.py:161: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_dp/modeling.py:178: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_dp/modeling.py:418: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_dp/modeling.py:499: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_dp/modeling.py:366: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_dp/modeling.py:680: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_dp/modeling.py:283: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:234: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:127: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:127: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/bert/bert_classifier.py:92: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/bert/bert_classifier.py:97: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-12 13:06:31.539 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/rubert_b]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:54: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "INFO:tensorflow:Restoring parameters from /content/rubert_b\n",
            "используется готовая модель\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2-Og8mYtirS"
      },
      "source": [
        "## Если вы хотите обучить модель самостоятельно"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VCq2vcv9Uv6",
        "cellView": "form",
        "outputId": "d728f2fd-0379-4eeb-8bdc-c6295e926351",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "source": [
        " #@title Загрузка обучающий выборки\n",
        " \n",
        "!wget https://competitions.codalab.org/my/datasets/download/b69d2de3-1aaa-4bad-985e-951aa9877690\n",
        "!unzip b69d2de3-1aaa-4bad-985e-951aa9877690 -d data_new"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-12 13:06:45--  https://competitions.codalab.org/my/datasets/download/b69d2de3-1aaa-4bad-985e-951aa9877690\n",
            "Resolving competitions.codalab.org (competitions.codalab.org)... 129.175.22.230\n",
            "Connecting to competitions.codalab.org (competitions.codalab.org)|129.175.22.230|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: https://newcodalab.lri.fr/prod-private/dataset_data_file/None/69950/public_data.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=8972f44402997f6d7df06f75c281e6199a391bde11343453e2021aac05e80a2a&X-Amz-Date=20201012T130646Z&X-Amz-Credential=AZIAIOSAODNN7EX123LE%2F20201012%2Fnewcodalab%2Fs3%2Faws4_request [following]\n",
            "--2020-10-12 13:06:46--  https://newcodalab.lri.fr/prod-private/dataset_data_file/None/69950/public_data.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=8972f44402997f6d7df06f75c281e6199a391bde11343453e2021aac05e80a2a&X-Amz-Date=20201012T130646Z&X-Amz-Credential=AZIAIOSAODNN7EX123LE%2F20201012%2Fnewcodalab%2Fs3%2Faws4_request\n",
            "Resolving newcodalab.lri.fr (newcodalab.lri.fr)... 129.175.15.21\n",
            "Connecting to newcodalab.lri.fr (newcodalab.lri.fr)|129.175.15.21|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 22460705 (21M) [application/zip]\n",
            "Saving to: ‘b69d2de3-1aaa-4bad-985e-951aa9877690’\n",
            "\n",
            "b69d2de3-1aaa-4bad- 100%[===================>]  21.42M  16.2MB/s    in 1.3s    \n",
            "\n",
            "2020-10-12 13:06:49 (16.2 MB/s) - ‘b69d2de3-1aaa-4bad-985e-951aa9877690’ saved [22460705/22460705]\n",
            "\n",
            "Archive:  b69d2de3-1aaa-4bad-985e-951aa9877690\n",
            "  inflating: data_new/test.csv       \n",
            "  inflating: data_new/train.csv      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nWEiAKWANOH"
      },
      "source": [
        "### Создание генератора данных для обучения модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6-lZy7MFl3r",
        "cellView": "form",
        "outputId": "5e507446-222a-4beb-9dce-0b21eb98a6b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "#@title Чтение данных\n",
        "import pandas as pd\n",
        "import csv\n",
        "import re\n",
        "import numpy as np\n",
        "import copy\n",
        "from deeppavlov.dataset_iterators.basic_classification_iterator import BasicClassificationDatasetIterator\n",
        " \n",
        "def my_reader(seed=42):\n",
        "    data = pd.read_csv('data_new/train.csv',  delimiter='\\t', quotechar='\"')    \n",
        "    test = pd.read_csv('data_new/test.csv',  delimiter='\\t', quotechar='\"') \n",
        "    data = data.dropna()\n",
        "    data['text'] = data['text'].str.replace('[-, a-z, A-Z, \\d, \\s, =, \", _, >, <, /, &, ;, :, !, @, /., /?]{20,}', ' ', regex=True)\n",
        "    print('data size', len(data))\n",
        "    train_split = 0.8 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "    train_split = int(len(data)*train_split)\n",
        "    data = data.sample(frac=1, random_state=1337).reset_index(drop=True)\n",
        "    data_train = data.iloc[:train_split]\n",
        "    data_val = data.iloc[train_split:]\n",
        "    mask = [(len(re.findall('[A-Z, a-z]', s)) < len(s)/4) for s in data_train['text']]\n",
        "    data_train = data_train.loc[mask]\n",
        " \n",
        "    print('train set')\n",
        "    mask_f = [c=='fake' for c in data_train['class']]# семплинг \n",
        "    mask_t = [c=='true' for c in data_train['class']]\n",
        "    data_f = data_train.loc[mask_f]\n",
        "    data_t = data_train.loc[mask_t]\n",
        "    print('all news:', len(data_train), '| fake news:', len(data_f), '| true news:', len(data_t))\n",
        "    data_ft = pd.concat([data_t, data_f])\n",
        "    balanse_k = 2 #@param {type:\"slider\", min:1, max:5, step:1}\n",
        "    for _ in range(1, balanse_k):\n",
        "        data_ft = pd.concat([data_ft, data_f])\n",
        "    mask_f = [c=='fake' for c in data_ft['class']]# семплинг \n",
        "    mask_t = [c=='true' for c in data_ft['class']]\n",
        "    data_f = data_ft.loc[mask_f] \n",
        "    data_t = data_ft.loc[mask_t]\n",
        "    print('all balanced news:', len(data_ft), '| fake balanced news:', len(data_f), '| true balanced news:', len(data_t))\n",
        "    \n",
        "    print('test set')\n",
        "    mask_f = [c=='fake' for c in data_val['class']]\n",
        "    mask_t = [c=='true' for c in data_val['class']]\n",
        "    data_f = data_val.loc[mask_f]\n",
        "    data_t = data_val.loc[mask_t]\n",
        "    print('all news:', len(data_val), '| fake news:', len(data_f), '| true news:', len(data_t))\n",
        "    \n",
        "    test_typles = list(test.to_records(index=False))\n",
        "    train = list(data_ft.to_records(index=False)) \n",
        " \n",
        " \n",
        "    np.random.seed(seed=seed)\n",
        "    np.random.shuffle(train)\n",
        "    vall = list(data_val.to_records(index=False)) \n",
        "    print('train:', len(train), '| vall:', len(vall), '| test:', len(test_typles))\n",
        "    return {'train':train, 'valid':vall, 'test':test_typles} \n",
        " \n",
        "my_data = my_reader()\n",
        "iterator = BasicClassificationDatasetIterator(my_data, seed=42, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data size 23878\n",
            "train set\n",
            "all news: 18924 | fake news: 3177 | true news: 15747\n",
            "all balanced news: 25278 | fake balanced news: 9531 | true balanced news: 15747\n",
            "test set\n",
            "all news: 4776 | fake news: 787 | true news: 3989\n",
            "train: 25278 | vall: 4776 | test: 6024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYuulxt5a0it",
        "cellView": "form"
      },
      "source": [
        "#@title Выборка\n",
        "data_type = 'train'#@param ['valid', 'train']\n",
        "\n",
        "iterator_copy = copy.deepcopy(iterator)\n",
        "iterator_copy = iterator_copy.gen_batches(data_type=data_type, batch_size=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRaFAJslJBbn",
        "cellView": "form",
        "outputId": "4e0dafe3-e0b1-4f88-e8e9-6613e388ec66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#@title Запустите, чтобы просмотреть новости в выборке\n",
        "def get_batch(iterator):\n",
        "    print(iterator[0][0])\n",
        "    print(iterator[1][0])\n",
        "\n",
        "get_batch(iterator_copy.__next__())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Главный тренер сборной России по баскетболу Василий Карасев похвалил игроков после поражения от Греции на чемпионате Европы. Об этом сообщает официальный сайт Российской федерации баскетбола РФБ.По словам тренера его подопечные провели неплохой матч с одной из сильнейших команд континента. Сегодня наша игра была более активной и сбалансированной чем в первом матче с Италией  отметил Карасев.Говоря о причинах поражения Карасев заявил что россияне в третьей четверти расслабились и потеряли концентрацию позволив грекам перехватить инициативу. Тренер отметил что не собирается ничего менять в игре своей команды.Карасев добавил что получил ценный тренерский опыт после игры с Грецией. Для меня все в новинку. Как игрок я прошел через все чемпионат Европы мира Олимпиада. Но в качестве тренера национальной команды  это всего лишь мой второй матч  подытожил тренер сборной.Игра Греции и России прошла вечером 5 августа и завершилась поражением подопечных Карасева со счетомВ первой игре на турнире россияне проиграли Италии 6976.Следующий матч сборная России проведет 7 сентября с командой Швеции.\n",
            "true\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifF7ehSUl7rr",
        "cellView": "form",
        "outputId": "2f7f5c55-dc5f-4002-d3da-9122f2a2f628",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        }
      },
      "source": [
        "#@title Проверьте находится ли новость в нашей выборке\n",
        "from functools import reduce\n",
        " \n",
        "data_type = 'train' #@param['valid', 'train']\n",
        "search = 'link' #@param {type:\"string\"}\n",
        " \n",
        "def serch_return(str, pattern=search):\n",
        "    if re.search(pattern, str[0]):\n",
        "        return str\n",
        "    else:\n",
        "        return None\n",
        " \n",
        "def str_sum(str, a):\n",
        "    if not isinstance(str, list):\n",
        "            str = [str]\n",
        "    if a:\n",
        "        if isinstance(str, list):\n",
        "            str.append(a)\n",
        "        else:\n",
        "            print('now list')\n",
        "            str = [a]\n",
        "    return str\n",
        " \n",
        "def find_news(data, news):\n",
        "    data_mask = list(map(serch_return, data))\n",
        "    answer = reduce(str_sum, data_mask)\n",
        "    return answer\n",
        " \n",
        "news = find_news(zip(iterator.get_instances(data_type=data_type)[0], iterator.get_instances(data_type=data_type)[1]), search)\n",
        "\n",
        "if news:\n",
        "    for n in news:\n",
        "        if n:\n",
        "            print('>>', n[1], '<<', '\\n', n[0], '\\n\\n==============================================\\n')\n",
        "        else:\n",
        "            print('новость в выборке не обноруженна')\n",
        "else:\n",
        "    print('новость в выборке не обноруженна')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "новость в выборке не обноруженна\n",
            ">> true << \n",
            " Сотовые операторы МТС и \"Вымпелком\" совместно с Facebook запустили в России сервис 0.facebook.com. Это облегченная версия крупнейшей социальной сети которая будет доступна бесплатно абонентам данных операторов. Об этом говорится в пресс-релизах обеих компаний.Посетителям 0.facebook.com не показываются изображения и фотографии. Если пользователь попытается их просмотреть или перейти на какой-либо внешний ресурс передача данных будет тарифицироваться по обычным расценкам.В мае 2010 года Facebook объявил об открытии сервиса 0.facebook.com для 50 мобильных операторов из 45 стран мира. В список попали в основном развивающиеся страны в частности Руанда Уганда и Никарагуа. Тогда Россия в перечень не вошла.Некоторые российские сотовые операторы уже предоставляют как бесплатный так и безлимитный сервис доступа к наиболее посещаемым ресурсам. Так абоненты Skylink могут за фиксированную плату посещать соцсеть \"Одноклассники\" и портал Mail.ru а абоненты \"Мегафона\" могут бесплатно заходить на \"Яндекс.Карты\". \n",
            "\n",
            "==============================================\n",
            "\n",
            ">> true << \n",
            " Компания Activision проиллюстрировала свежим видео как будут выглядеть многопользовательские перестрелки в шутереСемиминутный ролик посвящен особенностям экзоскелетов  специальных устройств которые позволят игрокам выполнять различные зрелищные приемы. Например передвигаться по полю быстрыми рывками и делать двойные прыжки. Также показана новая система настроек персонажей карты на которых развернутся сражения и один из готовящихся режимов  Uplink.Uplink можно сравнить с футуристическим баскетболом. Матч проходит между двумя командами каждая защищает свою корзину в которую противник пытается забросить дрона мяч. Тот кто держит дрона стрелять не может но ему разрешено использовать устройство как оружие ближнего боя.Ссвежий выпуск популярного цикла Call of Duty его готовят дляи PC. Речь в нем пойдет о войне которая идет на Земле в не столь отдаленном будущем. Игра появится в магазинах 4 ноября 2014 года. \n",
            "\n",
            "==============================================\n",
            "\n",
            ">> fake << \n",
            " Специалисты компании Neuralink основанной Илоном Маском продолжают наблюдения за свиньёй с вживлённым в мозг электронным чипом. Успехи животного несомненны  свинья уже закончила диссертацию на соискание степени доктора философии PhD.\n",
            "В ходе экспериментов Neuralink чипы внедрили в мозг трёх свиней. На двух из них проверяли безопасность операции. На третьей свинье исследуется влияние устройства на мышление. Учёные полагали что у свиньи существенно повысится обучаемость и способности к дрессировке. Однако они и не думали что эффект будет столь мощным.\n",
            "Через месяц после вживления чипа свинья научилась ассоциировать буквы на экране компьютера с образами. Затем она освоила обратный процесс  превращение образа в текст. Для этого пришлось создать оптическую клавиатуру выбор клавиш которой осуществляется направлением взгляда  печатать копытами пока невозможно.\n",
            "Через три месяца проанализировав собранную в интернете информацию свинья успешно сдала экзамены на степень бакалавра в Университете Беркли. Научным руководителем её докторской диссертации стал известный левый экономист и специалист по неравенству Эммануэль Саэс. Диссертация уже одобрена учёным советом Беркли и готова к защите.\n",
            "В своей работе свинья анализирует геополитические ошибки правительства США за последние двести лет. В частности она резко критикует присоединение Техаса в 1845 году и усиление сегрегации в северных штатах в 2020-м. Социальные реформы Барака Обамы напротив она считает весьма успешными. Главными проблемами Америки в диссертации названы социальное неравенство и избыточное финансирование полиции.\n",
            "Главная задача Neuralink сейчас  дать свинье имя. До сих пор её называли просто Свинья номер три. Однако по правилам Беркли соискатель докторской степени должен иметь имя и фамилию. Как только их выберут защита диссертации состоится.\n",
            " \n",
            "\n",
            "==============================================\n",
            "\n",
            ">> fake << \n",
            " Специалисты компании Neuralink основанной Илоном Маском продолжают наблюдения за свиньёй с вживлённым в мозг электронным чипом. Успехи животного несомненны  свинья уже закончила диссертацию на соискание степени доктора философии PhD.\n",
            "В ходе экспериментов Neuralink чипы внедрили в мозг трёх свиней. На двух из них проверяли безопасность операции. На третьей свинье исследуется влияние устройства на мышление. Учёные полагали что у свиньи существенно повысится обучаемость и способности к дрессировке. Однако они и не думали что эффект будет столь мощным.\n",
            "Через месяц после вживления чипа свинья научилась ассоциировать буквы на экране компьютера с образами. Затем она освоила обратный процесс  превращение образа в текст. Для этого пришлось создать оптическую клавиатуру выбор клавиш которой осуществляется направлением взгляда  печатать копытами пока невозможно.\n",
            "Через три месяца проанализировав собранную в интернете информацию свинья успешно сдала экзамены на степень бакалавра в Университете Беркли. Научным руководителем её докторской диссертации стал известный левый экономист и специалист по неравенству Эммануэль Саэс. Диссертация уже одобрена учёным советом Беркли и готова к защите.\n",
            "В своей работе свинья анализирует геополитические ошибки правительства США за последние двести лет. В частности она резко критикует присоединение Техаса в 1845 году и усиление сегрегации в северных штатах в 2020-м. Социальные реформы Барака Обамы напротив она считает весьма успешными. Главными проблемами Америки в диссертации названы социальное неравенство и избыточное финансирование полиции.\n",
            "Главная задача Neuralink сейчас  дать свинье имя. До сих пор её называли просто Свинья номер три. Однако по правилам Беркли соискатель докторской степени должен иметь имя и фамилию. Как только их выберут защита диссертации состоится.\n",
            " \n",
            "\n",
            "==============================================\n",
            "\n",
            ">> fake << \n",
            " Специалисты компании Neuralink основанной Илоном Маском продолжают наблюдения за свиньёй с вживлённым в мозг электронным чипом. Успехи животного несомненны  свинья уже закончила диссертацию на соискание степени доктора философии PhD.\n",
            "В ходе экспериментов Neuralink чипы внедрили в мозг трёх свиней. На двух из них проверяли безопасность операции. На третьей свинье исследуется влияние устройства на мышление. Учёные полагали что у свиньи существенно повысится обучаемость и способности к дрессировке. Однако они и не думали что эффект будет столь мощным.\n",
            "Через месяц после вживления чипа свинья научилась ассоциировать буквы на экране компьютера с образами. Затем она освоила обратный процесс  превращение образа в текст. Для этого пришлось создать оптическую клавиатуру выбор клавиш которой осуществляется направлением взгляда  печатать копытами пока невозможно.\n",
            "Через три месяца проанализировав собранную в интернете информацию свинья успешно сдала экзамены на степень бакалавра в Университете Беркли. Научным руководителем её докторской диссертации стал известный левый экономист и специалист по неравенству Эммануэль Саэс. Диссертация уже одобрена учёным советом Беркли и готова к защите.\n",
            "В своей работе свинья анализирует геополитические ошибки правительства США за последние двести лет. В частности она резко критикует присоединение Техаса в 1845 году и усиление сегрегации в северных штатах в 2020-м. Социальные реформы Барака Обамы напротив она считает весьма успешными. Главными проблемами Америки в диссертации названы социальное неравенство и избыточное финансирование полиции.\n",
            "Главная задача Neuralink сейчас  дать свинье имя. До сих пор её называли просто Свинья номер три. Однако по правилам Беркли соискатель докторской степени должен иметь имя и фамилию. Как только их выберут защита диссертации состоится.\n",
            " \n",
            "\n",
            "==============================================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wZMh_6VcHKO",
        "cellView": "form",
        "outputId": "45a974f3-fa84-438c-a778-c5c4a4a74546",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#@title Кодирование таргетов модели\n",
        "from deeppavlov.core.data.simple_vocab import SimpleVocabulary\n",
        "from deeppavlov.models.preprocessors.one_hotter import OneHotter\n",
        "try:\n",
        "    del iterator_copy\n",
        "except NameError:\n",
        "    pass\n",
        "vocab = SimpleVocabulary(save_path=\"./binary_classes.dict\")\n",
        "vocab.fit(iterator.get_instances(data_type=\"train\")[1])\n",
        "\n",
        "one_hotter = OneHotter(depth=vocab.len, \n",
        "                       single_vector=True \n",
        "                      )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-12 13:06:53.373 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 49: No load path is set for SimpleVocabulary in 'infer' mode. Using save path instead\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['true', 'fake']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PifesMQKslWW"
      },
      "source": [
        "### Цикл обучения модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1u6Lq2mqLJrt",
        "cellView": "form"
      },
      "source": [
        "#@title Функция валидации\n",
        "#@markdown Внимание при необходимости вы можете менять или добавлять готовые, или собственные метрики (по умолчанию используется F1 мера)\n",
        "import sklearn\n",
        "def progress(value, metrics, max, skip, save, mode):\n",
        "    return HTML(\"\"\"\n",
        "        <p>{mode}</p>\n",
        "        <p>{value}/{max}, batchs was skipped: {skip}</p>\n",
        "        <progress\n",
        "            value='{value}'\n",
        "            max='{max}',\n",
        "            style='width: 100%'\n",
        "        >\n",
        "            {value}\n",
        "        </progress>\n",
        "        <p>metrics: {m}</p>\n",
        "        <p>last save: {save}</p>\n",
        "    \"\"\".format(value=value, max=max, m=metrics, skip=skip, save=save, mode=mode))\n",
        " \n",
        "def evaluate(list_y_target, list_y_pred, metrics=[sklearn.metrics.f1_score]):\n",
        "    metrics_list = []\n",
        "    for metric in metrics: \n",
        "        result = metric(list_y_target,  list_y_pred)\n",
        "        metrics_list.append(result) \n",
        "    return metrics_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ITs_wpucHKq",
        "scrolled": true,
        "cellView": "form"
      },
      "source": [
        "#@title Запуск обучения\n",
        "#@markdown внимание это может занять несколько дней\n",
        " \n",
        "#@markdown ---\n",
        "from IPython.display import HTML, display\n",
        "from sklearn import metrics\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore') \n",
        " \n",
        "#@markdown укажите число эпох\n",
        "epochs = 2 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "#@markdown укажите размер батча\n",
        "batch_size=7 #@param {type:\"slider\", min:1, max:64, step:1}\n",
        "#@markdown укажите шаг валидации модели (прогресс обучения будет сохранен)\n",
        "vallidation_step = 800 #@param {type:\"slider\", min:100, max:1000, step:1}\n",
        "#@markdown в случае если эпоха была прерванна продолжите обучение с последнего обработанного батча\n",
        "stop_point =  0#@param {type:\"number\"}\n",
        "train_evaluate = True #@param {type:\"boolean\"}\n",
        "validation_evaluate = True #@param {type:\"boolean\"}\n",
        "metrics = [sklearn.metrics.f1_score, sklearn.metrics.accuracy_score]#@param {type:\"raw\"}\n",
        " \n",
        "train_batches = int(len(iterator.get_instances(data_type=\"train\")[0])/batch_size)\n",
        "valid_batches = int(len(iterator.get_instances(data_type=\"valid\")[0])/batch_size)\n",
        "for ep in range(epochs):\n",
        "    my_data = my_reader(ep)\n",
        "    iterator = BasicClassificationDatasetIterator(my_data, seed=42, shuffle=False)\n",
        "    print('epoch', ep+1)\n",
        "    out_train = display(progress(value=0, metrics=[], max=train_batches, skip=0, save=0, mode='train'), display_id=True)\n",
        "    train_y_pred=[]\n",
        "    train_y_target=[]\n",
        "    nbatches = 0\n",
        "    for x, y in iterator.gen_batches(batch_size=batch_size, \n",
        "                                     data_type=\"train\", shuffle=False):\n",
        "        nbatches += 1\n",
        "        if nbatches>=stop_point:\n",
        "            x_feat = bert_preprocessor(x)\n",
        "            y_onehot = one_hotter(vocab(y))\n",
        "            bert_classifier.train_on_batch(x_feat, y_onehot)\n",
        "            y_pred = bert_classifier(x_feat)\n",
        "            y_p_l=prob2labels(y_pred)\n",
        "            y_t_l=prob2labels(y_onehot)\n",
        "            train_y_pred+=y_p_l\n",
        "            train_y_target+=y_t_l\n",
        "             \n",
        "            if nbatches % 100 == 0:\n",
        "              stop_point=nbatches\n",
        "              bert_classifier.save()\n",
        " \n",
        "            if nbatches % vallidation_step == 0:\n",
        "                stop_point=nbatches\n",
        "                bert_classifier.save()\n",
        "                v_nbatches=0\n",
        "                out_val = display(progress(value=v_nbatches, metrics=0, max=valid_batches, skip=0, save=stop_point, mode='validate'), display_id=True)\n",
        "                val_y_pred=[]\n",
        "                val_y_target=[]\n",
        "                for x, y in iterator.gen_batches(batch_size=batch_size,\n",
        "                                      data_type=\"valid\", shuffle=False):\n",
        "                    v_nbatches+=1\n",
        "                    x_feat = bert_preprocessor(x)\n",
        "                    y_onehot = one_hotter(vocab(y))\n",
        "                    bert_classifier.train_on_batch(x_feat, y_onehot)\n",
        "                    y_pred = bert_classifier(x_feat)\n",
        "                    y_p_l=prob2labels(y_pred)\n",
        "                    y_t_l=prob2labels(y_onehot)\n",
        "                    val_y_pred+=y_p_l\n",
        "                    val_y_target+=y_t_l\n",
        "                    val_eval = evaluate(val_y_target,  val_y_pred, metrics=metrics)\n",
        "                    out_val.update(progress(value=v_nbatches, metrics=val_eval, max=valid_batches, skip=0, save=stop_point, mode='validate'))\n",
        "                \n",
        "            train_eval = evaluate(train_y_target, train_y_pred, metrics=metrics)\n",
        "            out_train.update(progress(value=nbatches, metrics=train_eval, max=train_batches, skip=stop_point, save=stop_point, mode='train'))\n",
        "            \n",
        "        else:\n",
        "            out_train.update(progress(value=nbatches, metrics=[], max=train_batches, skip=nbatches, save=stop_point, mode='train'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xstA37FL-o7i",
        "cellView": "form"
      },
      "source": [
        "#@title Получить csv файл предсказаний\n",
        "#@markdown Предсказание тестовой выборки и сохранение в следующую директорию\n",
        "path = '/content/drive/My Drive/predictions.csv' #@param {type:\"string\"}\n",
        "def predict(inp):\n",
        "    x_feat = bert_preprocessor(inp)\n",
        "    y_pred = bert_classifier(x_feat)\n",
        "    y_pred = prob2labels(y_pred)\n",
        "    y_pred = vocab(y_pred)\n",
        "    return y_pred\n",
        " \n",
        "nbvall=0 #6024\n",
        "with open(path, 'w', newline='') as csvfile:\n",
        "    fieldnames = ['text', 'class']\n",
        "    writer = csv.DictWriter(csvfile, delimiter='\\t', quotechar='\"', fieldnames=fieldnames)\n",
        "    writer.writeheader()\n",
        "    for x, _ in iterator.gen_batches(batch_size=1, data_type=\"test\", shuffle=False):\n",
        "        nbvall+=1\n",
        "        print(nbvall)\n",
        "        y_pred = predict(x)\n",
        "        for xi, ypi in zip(x, y_pred):\n",
        "            writer.writerow({'text': xi, 'class': ypi})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COKRoLVMMBQq"
      },
      "source": [
        "## Испытание модели\n",
        "###Насколько хорошо она работает?\n",
        "Довольно [неплохо](https://competitions.codalab.org/competitions/26284#results)(f1 score: 0.96893) но есть пара нюансов о которых [вам стоит знать](https://colab.research.google.com/drive/1nWdjgvjtMiOFIGEwvhIizd3naq16l9NN#scrollTo=Cs8C_hviF0I4&line=4&uniqifier=1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfLz2tfd7HRg",
        "cellView": "form"
      },
      "source": [
        "#@title Функция предсказания \n",
        " \n",
        "def predict(inp):\n",
        "    x_feat = bert_preprocessor(inp)\n",
        "    y_pred = bert_classifier(x_feat)\n",
        "    y_pred = prob2labels(y_pred)\n",
        "    y_pred = vocab(y_pred)\n",
        "    return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCPTDaxIL8nL",
        "cellView": "form",
        "outputId": "cf371d61-2d31-46cb-94c1-5b4877be0359",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#@title Демонстрация работы модели\n",
        "#@markdown Введите текст и запустите ячейку \n",
        " \n",
        "inp = '\\u0414\\u0435\\u043F\\u0443\\u0442\\u0430\\u0442\\u044B \\u0413\\u043E\\u0441\\u0434\\u0443\\u043C\\u044B \\u043F\\u0440\\u0438\\u043D\\u044F\\u043B\\u0438 \\u0437\\u0430\\u043A\\u043E\\u043D \\u043E \\u0432\\u0432\\u0435\\u0434\\u0435\\u043D\\u0438\\u0438 \\u043D\\u0430\\u043B\\u043E\\u0433\\u0430 \\u0437\\u0430 \\u0438\\u0441\\u043F\\u043E\\u043B\\u044C\\u0437\\u043E\\u0432\\u0430\\u043D\\u0438\\u0435 Wi-Fi \\u0440\\u043E\\u0443\\u0442\\u0435\\u0440\\u043E\\u0432. \\u041F\\u043E \\u043C\\u043D\\u0435\\u043D\\u0438\\u044E \\u043F\\u0430\\u0440\\u043B\\u0430\\u043C\\u0435\\u043D\\u0442\\u0430\\u0440\\u0438\\u0435\\u0432 \\u043A\\u0430\\u0436\\u0434\\u044B\\u0439 \\u043C\\u0430\\u0440\\u0448\\u0440\\u0443\\u0442\\u0438\\u0437\\u0430\\u0442\\u043E\\u0440 \\u043E\\u0431\\u043B\\u0430\\u0434\\u0430\\u0435\\u0442 \\u0441\\u043F\\u043E\\u0441\\u043E\\u0431\\u043D\\u043E\\u0441\\u0442\\u044C\\u044E \\u0438\\u0437\\u043B\\u0443\\u0447\\u0430\\u0442\\u044C \\u043E\\u043F\\u0430\\u0441\\u043D\\u044B\\u0435 \\u0434\\u043B\\u044F \\u0437\\u0434\\u043E\\u0440\\u043E\\u0432\\u044C\\u044F \\u0440\\u0430\\u0434\\u0438\\u043E\\u0432\\u043E\\u043B\\u043D\\u044B \\u0438 \\u043F\\u0435\\u0440\\u0435\\u0434\\u0430\\u0432\\u0430\\u0442\\u044C \\u0438\\u0445 \\u043D\\u0430 \\u0440\\u0430\\u0441\\u0441\\u0442\\u043E\\u044F\\u043D\\u0438\\u0435 \\u043E\\u0442 5 \\u0434\\u043E 10 \\u043A\\u043C \\u0441\\u043E\\u0437\\u0434\\u0430\\u0432\\u0430\\u044F \\u0442\\u0435\\u043C \\u0441\\u0430\\u043C\\u044B\\u043C \\u043E\\u043F\\u0430\\u0441\\u043D\\u043E\\u0441\\u0442\\u044C \\u0434\\u043B\\u044F \\u0437\\u0434\\u043E\\u0440\\u043E\\u0432\\u044C\\u044F \\u0433\\u0440\\u0430\\u0436\\u0434\\u0430\\u043D \\u0432 \\u0442\\u043E\\u043C \\u0447\\u0438\\u0441\\u043B\\u0435 \\u0442\\u0435\\u043C \\u043A\\u0442\\u043E \\u043D\\u0435 \\u043F\\u043E\\u043B\\u044C\\u0437\\u0443\\u0435\\u0442\\u0441\\u044F \\u0438\\u043D\\u0442\\u0435\\u0440\\u043D\\u0435\\u0442\\u043E\\u043C. \\u0421\\u0440\\u0435\\u0434\\u043D\\u0435\\u0441\\u0442\\u0430\\u0442\\u0438\\u0441\\u0442\\u0438\\u0447\\u0435\\u0441\\u043A\\u0438\\u0439 \\u043C\\u043D\\u043E\\u0433\\u043E\\u043A\\u0432\\u0430\\u0440\\u0442\\u0438\\u0440\\u043D\\u044B\\u0439 \\u0434\\u043E\\u043C \\u0441\\u043E\\u0441\\u0442\\u043E\\u0438\\u0442 \\u0438\\u0437 \\u0431\\u043E\\u043B\\u0435\\u0435 200 \\u043A\\u0432\\u0430\\u0440\\u0442\\u0438\\u0440 \\u0432 \\u0441\\u0440\\u0435\\u0434\\u043D\\u0435\\u0441\\u0442\\u0430\\u0442\\u0438\\u0441\\u0442\\u0438\\u0447\\u0435\\u0441\\u043A\\u043E\\u0439 \\u0440\\u043E\\u0441\\u0441\\u0438\\u0439\\u0441\\u043A\\u043E\\u0439 \\u0441\\u0435\\u043C\\u044C\\u0435 \\u043E\\u0434\\u043D\\u043E\\u0432\\u0440\\u0435\\u043C\\u0435\\u043D\\u043D\\u043E \\u043F\\u043E\\u043B\\u044C\\u0437\\u0443\\u044E\\u0442\\u0441\\u044F \\u0438\\u043D\\u0442\\u0435\\u0440\\u043D\\u0435\\u0442\\u043E\\u043C 3-4 \\u0447\\u0435\\u043B\\u043E\\u0432\\u0435\\u043A\\u0430. \\u0422\\u0430\\u043A\\u0436\\u0435 \\u043F\\u0440\\u0438\\u0448\\u0435\\u0434\\u0448\\u0430\\u044F \\u043A \\u043D\\u0430\\u043C \\u0441 \\u0417\\u0430\\u043F\\u0430\\u0434\\u0430 \\u0442\\u0435\\u0445\\u043D\\u043E\\u043B\\u043E\\u0433\\u0438\\u044F Wi-Fi \\u0438\\u0441\\u043F\\u043E\\u043B\\u044C\\u0437\\u0443\\u0435\\u0442\\u0441\\u044F \\u0432 \\u0437\\u0430\\u0432\\u0435\\u0434\\u0435\\u043D\\u0438\\u044F\\u0445 \\u043E\\u0431\\u0449\\u0435\\u043F\\u0438\\u0442\\u0430 \\u0438\\u043B\\u0438 \\u0432 \\u043A\\u0440\\u0443\\u043F\\u043D\\u044B\\u0445 \\u0442\\u043E\\u0440\\u0433\\u043E\\u0432\\u044B\\u0445 \\u0446\\u0435\\u043D\\u0442\\u0440\\u0430\\u0445. \\u0422\\u0430\\u043A\\u0438\\u043C \\u043E\\u0431\\u0440\\u0430\\u0437\\u043E\\u043C \\u043F\\u043E\\u0434\\u0432\\u0435\\u0440\\u0433\\u0430\\u044E\\u0442\\u0441\\u044F \\u043E\\u043F\\u0430\\u0441\\u043D\\u043E\\u0441\\u0442\\u0438 \\u0442\\u044B\\u0441\\u044F\\u0447\\u0438 \\u0447\\u0435\\u043B\\u043E\\u0432\\u0435\\u043A \\u0432\\u0435\\u0434\\u044C \\u0440\\u0430\\u0434\\u0438\\u0430\\u0446\\u0438\\u043E\\u043D\\u043D\\u044B\\u0439 \\u0444\\u043E\\u043D \\u043F\\u0440\\u0435\\u0432\\u044B\\u0448\\u0430\\u0435\\u0442 \\u0442\\u043E\\u0442 \\u0447\\u0442\\u043E \\u0437\\u0430\\u0444\\u0438\\u043A\\u0441\\u0438\\u0440\\u043E\\u0432\\u0430\\u043D \\u0432 \\u0427\\u0435\\u0440\\u043D\\u043E\\u0431\\u044B\\u043B\\u0435.  ' #@param {type:\"string\"} \n",
        "prediction = predict([inp]) \n",
        "print('предсказание:', prediction[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "предсказание: fake\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pR4A6bxT5jUP"
      },
      "source": [
        "# Послесловие"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7Kh-zO052bK"
      },
      "source": [
        "Разработка проекта продолжается, мы не собираемся останавливаться на достигнутом и намерены улучшать текущие показатели.\n",
        "\n",
        "Хотим выразить благодарность Google Colaboratory за бесплатные вычислительные ресурсы, deeppavlov за предобученные модели, Сбер Банку за предоставленную обучающую выборку и организаторам архипелага и leader-id за предоставленную возможность участия.\n",
        "\n",
        "Отдельное спасибо хотим сказать нашим научным руководителям и заведующему кафедрой.\n"
      ]
    }
  ]
}